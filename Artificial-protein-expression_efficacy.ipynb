{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial protein expression screening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Computes the change in network relative entropy from viral PPIs after setting immune system proteins, one at a time, to high abundance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import copy as copy\n",
    "from tqdm.notebook import tqdm\n",
    "import math\n",
    "import scipy.stats as st\n",
    "\n",
    "from CoRe import reader\n",
    "from CoRe.ncip import ncip\n",
    "from CoRe.BA_C import BA\n",
    "\n",
    "import importlib\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = \"./Examples/Immune_System\"\n",
    "os.chdir(data_directory)\n",
    "\n",
    "edge_data = pd.read_pickle('Immune_System_medium-PPI-edges.pkl')\n",
    "node_data = pd.read_pickle('Immune_System_medium-PPI-nodes.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "remake_graph = False\n",
    "\n",
    "if remake_graph==False:\n",
    "    netObj = ncip()\n",
    "    netObj.load_graph('Immune_System-medium-PPI.gml')\n",
    "else:\n",
    "    netObj = ncip()\n",
    "    netObj.load_data(edge_data,node_data)\n",
    "    netObj.make_graph()\n",
    "    netObj.save_network(pathway_nametag,network_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**All immune system communication network proteins that have PPI with SARS-CoV-2 proteins**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PTGES2', 'CYB5R3', 'HECTD1', 'EIF4E2', 'ELOC', 'IMPDH2', 'SLC27A2', 'IL17RA', 'SLC44A2', 'ERP44', 'ANO6', 'NPC2', 'NLRX1', 'RAB18', 'CSNK2B', 'RAB14', 'ELOB', 'ECSIT', 'GGH', 'STOM', 'ITGB1', 'AP2A2', 'HMOX1', 'RAB5C', 'RAB10', 'RNF41', 'GLA', 'RIPK1', 'NEU1', 'RALA', 'RAB7A', 'TOMM70', 'TBK1', 'PVR', 'GOLGA7', 'RHOA']\n"
     ]
    }
   ],
   "source": [
    "f = open('SARS_CoV2-Immune_System_interactions.json')\n",
    "SARS_nodes = json.load(f)\n",
    "f.close()\n",
    "\n",
    "all_sars_nodes = []\n",
    "\n",
    "for s in SARS_nodes.keys():\n",
    "    all_sars_nodes += SARS_nodes[s]\n",
    "    \n",
    "all_sars_nodes = list(set(all_sars_nodes))\n",
    "\n",
    "print(all_sars_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specifying the reference state and construction of the global transition matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0.] [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "initial_state_type = 'maxEnt'\n",
    "\n",
    "errorname = '0.0'\n",
    "rho = float(errorname)\n",
    "\n",
    "input_bits = 1\n",
    "code_length = int(2**input_bits)\n",
    "\n",
    "max_entropy_state = (1.0/float(code_length))*np.ones(shape=(code_length,))\n",
    "\n",
    "low_state = np.zeros(shape=(code_length,))\n",
    "low_state[-1] = 1.0\n",
    "\n",
    "high_state = np.zeros(shape=(code_length,))\n",
    "high_state[0] = 1.0\n",
    "\n",
    "if initial_state_type=='high':\n",
    "    initial_state = high_state\n",
    "elif initial_state_type=='low':\n",
    "    initial_state = low_state\n",
    "else:\n",
    "    initial_state = max_entropy_state\n",
    "\n",
    "print(high_state,low_state)\n",
    "\n",
    "netObj.construct_C(rho,h=input_bits,neglect_modules=[])\n",
    "node_list = list(netObj.G_d.nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Disconnect all drugs from the network initially**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "netObj.disconnect_drug_nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute the reference stationary state of the network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference state relative entropy:  0.0\n"
     ]
    }
   ],
   "source": [
    "initial_network_state = np.zeros(shape=(netObj.C_sparse.shape[0],1))\n",
    "network_sources = {}\n",
    "\n",
    "for n in range(0,len(node_list)):\n",
    "    initial_network_state[code_length*n:code_length*(n+1),0] = initial_state\n",
    "    \n",
    "network_sources = []\n",
    "\n",
    "reference_final_state, steps = netObj.get_final_state(initial_network_state,[])\n",
    "reference_final_entropy = netObj.state_entropy(reference_final_state,[])\n",
    "print('Reference state relative entropy: ',reference_final_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set the SARS-CoV-2 nodes in the network to low abundance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7fc03112b9b4ae580184870ba300810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "network_state = np.zeros(shape=(netObj.C_sparse.shape[0],1))\n",
    "network_sources = []\n",
    "\n",
    "for n in range(0,len(node_list)):\n",
    "    network_state[code_length*n:code_length*(n+1),0] = initial_state\n",
    "\n",
    "for k in tqdm(SARS_nodes.keys()):\n",
    "    for n in SARS_nodes[k]:\n",
    "        try:\n",
    "            i = node_list.index(n)\n",
    "\n",
    "            network_state[netObj.code_length*i:netObj.code_length*(i+1),0] = low_state\n",
    "\n",
    "            if i not in network_sources:\n",
    "                network_sources.append(i)\n",
    "        except ValueError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Relative entropy of the total network and number of steps to stationary state.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_state, steps = netObj.get_final_state(network_state,network_sources)\n",
    "final_entropy = netObj.state_entropy(final_state,network_sources)\n",
    "print(final_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_class = nx.get_node_attributes(netObj.G_d,\"class\")\n",
    "node_n = list(netObj.G_d.nodes())\n",
    "\n",
    "c = 0\n",
    "\n",
    "for i in range(0,len(node_n)):\n",
    "    nn = node_n[i]\n",
    "    if node_class[nn]=='EntityWithAccessionedSequence':\n",
    "        relH = st.entropy(final_state[netObj.code_length*i:netObj.code_length*(i+1),0],max_entropy_state,base=2)\n",
    "        \n",
    "        if relH>0.01:\n",
    "            c += 1\n",
    "            \n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_entropy,steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sources = []\n",
    "\n",
    "for n in netObj.G_d.nodes(data=True):\n",
    "    #if netObj.G_d.in_degree(n[0])==0:\n",
    "    #    if n[1]['class']=='EntityWithAccessionedSequence' or n[1]['class']=='Complex':\n",
    "    if n[1]['class']=='EntityWithAccessionedSequence' and n[0] not in all_sars_nodes:\n",
    "            all_sources.append((n[0],netObj.G_d.in_degree(n[0])))\n",
    "            \n",
    "print(len(all_sources))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_shifts = {}\n",
    "H_drops = {}\n",
    "H_gains = {}\n",
    "\n",
    "for s_pair in tqdm(all_sources):\n",
    "    s = s_pair[0]\n",
    "    additional_source_nodes = [s]\n",
    "    \n",
    "    netObj.construct_C(rho,h=input_bits)\n",
    "    netObj.disconnect_nodes('ChemicalDrug',additional_source_nodes)\n",
    "    netObj.disconnect_nodes('ProteinDrug',additional_source_nodes)\n",
    "    \n",
    "    network_state = np.zeros(shape=(netObj.C_sparse.shape[0],1))\n",
    "    network_sources = []\n",
    "    \n",
    "    for n in range(0,len(node_list)):\n",
    "        network_state[code_length*n:code_length*(n+1),0] = initial_state\n",
    "\n",
    "    for k in SARS_nodes.keys():\n",
    "        for n in SARS_nodes[k]:\n",
    "            try:\n",
    "                i = node_list.index(n)\n",
    "\n",
    "                network_state[netObj.code_length*i:netObj.code_length*(i+1),0] = low_state\n",
    "\n",
    "                network_sources.append(i)\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "        for n in additional_source_nodes:\n",
    "            try:\n",
    "                i = node_list.index(n)\n",
    "\n",
    "                network_state[netObj.code_length*i:netObj.code_length*(i+1),0] = high_state\n",
    "\n",
    "                network_sources.append(i)\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "        #print(np.linalg.norm(network_state[k],1),len(network_sources[k]))\n",
    "        \n",
    "    entropy_shifts[s] = 0.0\n",
    "\n",
    "    this_state, steps = netObj.get_final_state(network_state,network_sources)\n",
    "    this_entropy = netObj.state_entropy(this_state,network_sources)\n",
    "    H_drop, H_gain = netObj.entropy_drop_and_rise(this_state,final_state,reference_final_state,network_sources)\n",
    "                \n",
    "    entropy_shifts[s] = this_entropy\n",
    "        \n",
    "    H_drops[s] = H_drop\n",
    "    H_gains[s] = H_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.chdir(data_directory+'/counter_entropic_shift')\n",
    "except OSError:\n",
    "    os.mkdir(data_directory+'/counter_entropic_shift')\n",
    "    os.chdir(data_directory+'/counter_entropic_shift')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_data = nx.get_node_attributes(netObj.G_d,\"name\")\n",
    "node_class = nx.get_node_attributes(netObj.G_d,\"class\")\n",
    "\n",
    "of = open('high_all_protein_shifts.csv','w')\n",
    "\n",
    "print('Gene,Relative Entropy,In Degree',file=of)\n",
    "\n",
    "print('Ref,'+str(final_entropy)+',0',file=of)\n",
    "\n",
    "for s in all_sources:\n",
    "    if node_class[s[0]]==\"Complex\":\n",
    "        this_name = node_data[s[0]]\n",
    "        this_name = this_name.replace(',',';')\n",
    "    else:\n",
    "        this_name = s[0]\n",
    "        \n",
    "    print(this_name+','+str(entropy_shifts[s[0]])+','+str(s[1]),file=of)\n",
    "    \n",
    "of.close()\n",
    "\n",
    "of = open('split_all_high_protein_shifts-'+initial_state_type+'.csv','w')\n",
    "\n",
    "print('Protein,Drop,Gain',file=of)\n",
    "\n",
    "for s in all_sources:\n",
    "    if node_class[s[0]]==\"Complex\":\n",
    "        this_name = node_data[s[0]]\n",
    "        this_name = this_name.replace(',',';')\n",
    "    else:\n",
    "        this_name = s[0]\n",
    "        \n",
    "    print(this_name+','+str(H_drops[s[0]])+','+str(H_gains[s[0]]),file=of)\n",
    "    \n",
    "of.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
